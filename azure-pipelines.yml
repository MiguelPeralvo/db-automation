# mlFlow Registry QA & Prod pipeline
variables:
- group: Databricks-environment
- group: Pipeline-variables

trigger:
  branches:
    exclude:
      - master
    include:
      - staging
      - releases/*

pool:
  name: Hosted Ubuntu 1604

steps:
- task: UsePythonVersion@0
  displayName: 'Use Python 3.7'
  inputs:
    versionSpec: 3.7

- script: |
    pip install pytest requests setuptools wheel pyspark==2.4.5
#    pip install -U databricks-cli
  displayName: 'Load Python Dependencies'

- task: riserrad.azdo-databricks.azdo-databricks-configuredatabricks.configuredatabricks@0
  inputs:
    url: '$(WORKSPACE_REGION_URL)/?o=$(WORKSPACE_ORG_ID)'
    token: '$(DATABRICKS_TOKEN)'
  displayName: 'Configure Databricks CLI for AZDO'

#- script: |
#    dbfs ls
#  displayName: 'Check config working'

- checkout: self
  persistCredentials: true
  clean: true

- script: |
    git pull
#   git checkout $(Build.SourceBranch)
  displayName: 'Get Latest from Branch $(Build.SourceBranchName) / $(Build.SourceBranch)'

- script: |
    cat /home/vsts/.databrickscfg
    echo ""
    echo "-------------"
    databricks workspace mkdirs /Shared/db-automation/train --profile AZDO
    databricks workspace import $(Build.Repository.LocalPath)/"pipeline/ML/train/train_model.py" "/Shared/db-automation/train/train_model"  --language PYTHON -o --profile AZDO
  displayName: 'Import ML Train Notebook'

- task: PythonScript@0
  inputs:
    scriptSource: 'filePath'
    scriptPath: '$(Build.Repository.LocalPath)/cicd-scripts/executenotebook.py'
    arguments: '--shard $(WORKSPACE_REGION_URL) --token $(DATABRICKS_TOKEN) --cluster $(EXISTING_CLUSTER_ID) --localpath $(Build.Repository.LocalPath)/pipeline/ML/train --workspacepath /Shared/db-automation/train --outfilepath /home/vsts/work/1/s/pipeline --params model_name=$(MODEL_NAME)'
  displayName: 'Train the new version of the model'

- script: |
    cat /home/vsts/.databrickscfg
    echo ""
    echo "-------------"
    databricks workspace mkdirs /Shared/db-automation/batch_test --profile AZDO
    databricks workspace import $(Build.Repository.LocalPath)/"pipeline/ML/batch_test/deploy_test_databricks_batch_ml_model.py" "/Shared/db-automation/batch_test/deploy_test_databricks_batch_ml_model"  --language PYTHON -o --profile AZDO
  displayName: 'Import ML Batch Deploy/Test Notebook'

- task: PythonScript@0
  inputs:
    scriptSource: 'filePath'
    scriptPath: '$(Build.Repository.LocalPath)/cicd-scripts/executenotebook.py'
    arguments: '--shard $(WORKSPACE_REGION_URL) --token $(DATABRICKS_TOKEN) --cluster $(EXISTING_CLUSTER_ID) --localpath $(Build.Repository.LocalPath)/pipeline/ML/batch_test --workspacepath /Shared/db-automation/batch_test --outfilepath /home/vsts/work/1/s/pipeline --params model_name=$(MODEL_NAME)'
  displayName: 'Deploy and test mlFlow Model from Registry to Databricks batch'

- script: |
    echo $(response)
  displayName: 'Batch test result'


#- script: |
#    cat /home/vsts/.databrickscfg
#    echo ""
#    echo "-------------"
#    databricks workspace mkdirs /Shared/db-automation/deploy --profile AZDO
#    databricks workspace import $(Build.Repository.LocalPath)/"pipeline/ML/deploy/deploy_azure_ml_model.py" "/Shared/db-automation/deploy/deploy_azure_ml_model"  --language PYTHON -o --profile AZDO
#  displayName: 'Import ML Deploy Notebook'
#
#- task: PythonScript@0
#  inputs:
#    scriptSource: 'filePath'
#    scriptPath: '$(Build.Repository.LocalPath)/cicd-scripts/executenotebook.py'
#    arguments: '--shard $(WORKSPACE_REGION_URL) --token $(DATABRICKS_TOKEN) --cluster $(EXISTING_CLUSTER_ID) --localpath $(Build.Repository.LocalPath)/pipeline/ML/deploy --workspacepath /Shared/db-automation/deploy --outfilepath /home/vsts/work/1/s/pipeline --params model_name=$(MODEL_NAME)'
#  displayName: 'Deploy mlFlow Model from Registry to Azure ML for Testing'
#
#- script: |
#    echo $(response)
#  displayName: 'API URL'
#
#- script: |
#    cat /home/vsts/.databrickscfg
#    echo ""
#    echo "-------------"
#    databricks workspace mkdirs /Shared/db-automation/test --profile AZDO
#    databricks workspace import $BUILD_SOURCESDIRECTORY/"pipeline/ML/test/test_api.py" "/Shared/db-automation/test/test_api"  --language PYTHON -o --profile AZDO
#  displayName: 'Import ML Test Notebook'
#
#- task: PythonScript@0
#  inputs:
#    scriptSource: 'filePath'
#    scriptPath: '$(Build.Repository.LocalPath)/cicd-scripts/executenotebook.py'
#    arguments: '--shard $(WORKSPACE_REGION_URL) --token $(DATABRICKS_TOKEN) --cluster $(EXISTING_CLUSTER_ID) --localpath $(Build.Repository.LocalPath)/pipeline/ML/test --workspacepath /Shared/db-automation/test --outfilepath /home/vsts/work/1/s/pipeline --params model_name=$(MODEL_NAME),scoring_uri=$(response)'
#  displayName: 'Test mlFlow Model from Registry against REST API'

#- task: PythonScript@0
#  inputs:
#    scriptSource: 'filePath'
#    scriptPath: '$(Build.Repository.LocalPath)/cicd-scripts/mlflow.py'
#    arguments: ''
#  displayName: 'Promote mlFlow Registry model to Production'
#
#- script: |
#    echo $(response)
#  displayName: 'Model Production Version'
#
#- task: PythonScript@0
#  inputs:
#    scriptSource: 'filePath'
#    scriptPath: '$(Build.Repository.LocalPath)/cicd-scripts/executenotebook.py'
#    arguments: '--shard $(WORKSPACE_REGION_URL) --token $(DATABRICKS_TOKEN) --cluster $(EXISTING_CLUSTER_ID) --localpath $(Build.Repository.LocalPath)/pipeline/ML/deploy --workspacepath /Demo/Test --outfilepath /home/vsts/work/1/s/pipeline --params model_name=$(MODEL_NAME),stage="production,phase="prod"'
#  displayName: 'Deploy mlFlow Model from Registry to Azure ML into Production'